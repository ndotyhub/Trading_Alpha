{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from pandas.io.json import json_normalize\n",
    "import urllib.request as urlreq\n",
    "import json\n",
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "import datetime as dt\n",
    "from yahoofinancials import YahooFinancials\n",
    "import os\n",
    "\n",
    "def update_progress(progress, date_str):\n",
    "    bar_length = 90\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}% Status: {2}\".format( \"#\" * block + \"-\" * (bar_length - block), \n",
    "                                                      progress * 100,\n",
    "                                                      date_str)\n",
    "    print(text)\n",
    "\n",
    "\n",
    "def scrape_table_helper(earnings_soup):\n",
    "\n",
    "    headers = [th.text for th in earnings_soup.find('tr', {'data-reactid': '19'}).find_all('th')]\n",
    "    curr_dict = {header:[] for header in headers}\n",
    "\n",
    "    for row in earnings_soup.find('tbody').find_all('tr'):\n",
    "        curr_row_text = [td.text for td in row.find_all('td')]\n",
    "\n",
    "        for i, val in enumerate(curr_row_text):\n",
    "            curr_dict[headers[i]].append(val)\n",
    "\n",
    "    earnings_df = pd.DataFrame(curr_dict)\n",
    "    \n",
    "    return earnings_df\n",
    "\n",
    "def scrape_table(earnings_url):\n",
    "\n",
    "    earnings_soup = bs(requests.get(earnings_url.format(dt, 0)).text, 'lxml')\n",
    "\n",
    "    earnings_soup = earnings_soup.find(\"div\", {\"id\": \"fin-cal-table\"})\n",
    "\n",
    "    total_names = earnings_soup.find('span', {'data-reactid':'8'}).text.replace('results','').strip().split(' ')[-1]\n",
    "\n",
    "    if total_names.isnumeric():\n",
    "        total_names = int(total_names)\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    num_of_offsets = total_names//100\n",
    "    offset_range = [offset*100 for offset in list(range(1, 1 + num_of_offsets))]\n",
    "\n",
    "    earnings_dfs = [scrape_table_helper(earnings_soup)]\n",
    "\n",
    "    for offset in offset_range:\n",
    "        offset_url = earnings_url + '&offset={}&size=100'.format(offset)\n",
    "        earnings_soup = bs(requests.get(offset_url).text, 'lxml')\n",
    "        earnings_soup = earnings_soup.find(\"div\", {\"id\": \"fin-cal-table\"})\n",
    "        earnings_dfs.append(scrape_table_helper(earnings_soup))\n",
    "\n",
    "    earnings_df = pd.concat(earnings_dfs, axis = 0).drop_duplicates().reset_index(drop = True)\n",
    "    \n",
    "    return earnings_df\n",
    "\n",
    "def ticker_earnings(ticker_check, curr_prices):\n",
    "\n",
    "    curr_prices['formatted_date'] = pd.to_datetime(curr_prices['formatted_date'])\n",
    "\n",
    "    curr_earnings = all_earnings_df[all_earnings_df.Symbol == ticker_check].reset_index(drop = True)\n",
    "    curr_earnings['Price_Before'] = np.nan\n",
    "    curr_earnings['Price_After'] = np.nan\n",
    "    curr_earnings['Earnings_Change'] = np.nan\n",
    "\n",
    "    for idx, row in curr_earnings.iterrows():\n",
    "        earnings_date = row['Earnings Date']\n",
    "        price_before = curr_prices[curr_prices.formatted_date <= earnings_date].sort_values('formatted_date', ascending = False).head(2).reset_index(drop = True).loc[1,'adjclose']\n",
    "        price_after = curr_prices[curr_prices.formatted_date >= earnings_date].sort_values('formatted_date').head(2).reset_index(drop = True).loc[1, 'adjclose']\n",
    "        curr_earnings.loc[idx, 'Price_Before'] = price_before\n",
    "        curr_earnings.loc[idx, 'Price_After'] = price_after\n",
    "        curr_earnings.loc[idx, 'Earnings_Change'] = price_after/price_before - 1\n",
    "\n",
    "    return curr_earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_date = dt.datetime(2017,1,1)\n",
    "end_date = dt.datetime.today()\n",
    "\n",
    "date_list = [day.strftime('%Y-%m-%d') for day in list(filter(lambda day: day.weekday() not in [5, 6], \n",
    "                                                             [start_date + dt.timedelta(day) for day in range((end_date - start_date).days + 1)]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\Fang\\Desktop\\Python Trading\\Trading\\Data\\Historical Queries\\Yahoo Earnings Calendar')\n",
    "\n",
    "if 'hist_earnings.csv' in os.listdir():\n",
    "    all_earnings_df = pd.read_csv('hist_earnings.csv', parse_dates = ['Earnings Date'],\n",
    "                                 index_col = 0)\n",
    "else:\n",
    "    base_earnings_url = 'https://finance.yahoo.com/calendar/earnings?day='\n",
    "\n",
    "    all_earnings = []\n",
    "\n",
    "    for i, date_str in enumerate(date_list):\n",
    "        curr_url = base_earnings_url + date_str\n",
    "        \n",
    "        scrape_failed = True\n",
    "        \n",
    "        while scrape_failed:\n",
    "            try:\n",
    "                curr_df = scrape_table(curr_url)\n",
    "                if type(curr_df) != bool:\n",
    "                    curr_df['Earnings Date'] = dt.datetime.strptime(date_str, '%Y-%m-%d')\n",
    "                    all_earnings.append(curr_df)\n",
    "                scrape_failed = False\n",
    "            except:\n",
    "                time.sleep(0.5)\n",
    "\n",
    "        update_progress(i / len(date_list), date_str)\n",
    "\n",
    "    update_progress(1, date_str)\n",
    "\n",
    "    all_earnings_df = pd.concat(all_earnings, axis = 0)\n",
    "    \n",
    "    all_earnings_df.to_csv('hist_earnings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_names = all_earnings_df[['Symbol','Earnings Date']].groupby('Symbol').min().sort_values('Earnings Date').reset_index()\n",
    "\n",
    "batch_partions = range(len(batch_names))\n",
    "\n",
    "batch_n = 50\n",
    "\n",
    "batch_partitions = [batch_partions[i*batch_n: (i + 1)*batch_n] for i in range(len(batch_partions)//batch_n + 1)]\n",
    "\n",
    "batch_partitions = [batch_names.iloc[batch_range,:] for batch_range in batch_partitions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [#########################################################################################-] 99.1% Status: 1.368561085065206\n"
     ]
    }
   ],
   "source": [
    "failed_batches = []\n",
    "\n",
    "price_dict = {}\n",
    "\n",
    "earnings_dict = []\n",
    "\n",
    "for i, batch in enumerate(batch_partitions[::-1]):\n",
    "    start_time = time.time()\n",
    "    query_completed = False\n",
    "    \n",
    "    tick_batch = batch.Symbol.tolist()\n",
    "    \n",
    "    hist_start_date = batch['Earnings Date'].min() - dt.timedelta(days = 3)\n",
    "    \n",
    "    try:\n",
    "        yahoo_financials = YahooFinancials(tick_batch)\n",
    "        historical_stock_prices = yahoo_financials.get_historical_price_data(hist_start_date.strftime('%Y-%m-%d'), \n",
    "                                                                             dt.datetime.today().strftime('%Y-%m-%d'),\n",
    "                                                                             'daily')\n",
    "        query_completed = True\n",
    "    except:\n",
    "        failed_batches.append(tick_batch)\n",
    "        continue\n",
    "    \n",
    "    if query_completed:\n",
    "        \n",
    "        for ticker in historical_stock_prices.keys():\n",
    "            try:\n",
    "                price_dict[ticker] = pd.DataFrame(historical_stock_prices[ticker]['prices'])\n",
    "\n",
    "                curr_prices = price_dict[ticker]\n",
    "\n",
    "                earnings_dict.append(ticker_earnings(ticker, curr_prices))\n",
    "            except:\n",
    "                continue\n",
    "    end_time = time.time()\n",
    "    update_progress(i / len(batch_partitions), str(round((end_time - start_time)/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "earnings_hist = pd.concat(earnings_dict, axis = 0)\n",
    "earnings_hist.to_csv('earnings_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(failed_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yahoo_financials = YahooFinancials(['TSLA','NVDA','AMD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "earnings_data_json = yahoo_financials.get_stock_earnings_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quarterly': [{'date': '4Q2018', 'actual': 1.93, 'estimate': 2.2},\n",
       "  {'date': '1Q2019', 'actual': -2.9, 'estimate': -0.69},\n",
       "  {'date': '2Q2019', 'actual': -1.12, 'estimate': -0.36},\n",
       "  {'date': '3Q2019', 'actual': 1.86, 'estimate': -0.42}],\n",
       " 'currentQuarterEstimate': 1.29,\n",
       " 'currentQuarterEstimateDate': '4Q',\n",
       " 'currentQuarterEstimateYear': 2019,\n",
       " 'earningsDate': [{'raw': 1580169600, 'fmt': '2020-01-28'},\n",
       "  {'raw': 1580688000, 'fmt': '2020-02-03'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earnings_data_json['TSLA']['earningsData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat(earnings_dict, axis = 0).to_csv('test_earnings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ticker = 'NVDA'\n",
    "\n",
    "modules = '%2C'.join(['assetProfile','incomeStatementHistory', 'balanceSheetHistoryQuarterly',\n",
    "                              'balanceSheetHistory','cashflowStatementHistory', 'cashflowStatementHistoryQuarterly',\n",
    "                              'defaultKeyStatistics','financialData','incomeStatementHistoryQuarterly',\n",
    "                              'calendarEvents','secFilings', 'recommendationTrend', 'institutionOwnership',\n",
    "                              'fundOwnership', 'majorDirectHolders', 'majorHoldersBreakdown',\n",
    "                              'insiderTransactions', 'insiderHolders', 'netSharePurchaseActivity',\n",
    "                              'earnings', 'earningsHistory', 'earningsTrend', 'industryTrend', 'indexTrend',\n",
    "                              'sectorTrend'])\n",
    "full_info_url = 'https://query1.finance.yahoo.com/v10/finance/quoteSummary/{0}?modules={1}'.format(ticker, modules)\n",
    "\n",
    "full_info_json = json.loads(requests.get(full_info_url).text)\n",
    "profile_json = full_info_json['quoteSummary']['result'][0]['assetProfile']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Technology'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_json['industry']\n",
    "profile_json['sector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
